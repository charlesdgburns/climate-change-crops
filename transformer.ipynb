{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":81000,"databundleVersionId":8812083,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nHello Future Crop friends!\n\nI've appreciated learning about crop stages and growing-degree days. However, I'm left wondering how well we could generalise with unsupervised methods. Can modern machine-learning techniques really not keep up with domain knowledge?\n\n**Can we train a transformer to understand relationships between location, crop-type, time-by-time inputs ($c_t$), and the yield?**\n\nLet's follow the so-called 'scaling laws', just chucking all our data into one big fella and train it to heck.\n\nWe feed every data example as inputs (static inputs and time-by-time inputs).\n- The network is trained to be generative, recovering masked inputs.\n- Then predictions are made by masking only the yield input.","metadata":{}},{"cell_type":"markdown","source":"# Data: a first look\n\nThe first thing to notice about the dataset, which will help us speed up training, is that there's large variability in the location and crop.\nFurthermore, location data fully predicts soil-type and soil nitrogen levels, so we can ignore this data. However, different locations are used more for different crops, so the crop type is still relevant.","metadata":{}},{"cell_type":"code","source":"# General setup\nimport os\nimport gc\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch #for training\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\n\n#global variables\nDATA_DIR = r'/kaggle/input/the-future-crop-challenge'\nDEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nprint(f'Running on {DEVICE}')\n\ndef setup_seed(seed):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    return\n\nsetup_seed(2025) #For reproducibility, set seed to current year\n\n# Check that the kaggle data is all there:\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-25T23:41:43.518136Z","iopub.execute_input":"2025-11-25T23:41:43.518397Z","iopub.status.idle":"2025-11-25T23:41:44.929003Z","shell.execute_reply.started":"2025-11-25T23:41:43.518376Z","shell.execute_reply":"2025-11-25T23:41:44.928252Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/the-future-crop-challenge/pr_wheat_train.parquet\n/kaggle/input/the-future-crop-challenge/tasmax_maize_train.parquet\n/kaggle/input/the-future-crop-challenge/sample_submission.csv\n/kaggle/input/the-future-crop-challenge/soil_co2_wheat_train.parquet\n/kaggle/input/the-future-crop-challenge/tas_wheat_train.parquet\n/kaggle/input/the-future-crop-challenge/rsds_maize_train.parquet\n/kaggle/input/the-future-crop-challenge/tasmin_wheat_train.parquet\n/kaggle/input/the-future-crop-challenge/tasmax_wheat_train.parquet\n/kaggle/input/the-future-crop-challenge/rsds_maize_test.parquet\n/kaggle/input/the-future-crop-challenge/soil_co2_maize_test.parquet\n/kaggle/input/the-future-crop-challenge/train_solutions_maize.parquet\n/kaggle/input/the-future-crop-challenge/pr_maize_test.parquet\n/kaggle/input/the-future-crop-challenge/tas_wheat_test.parquet\n/kaggle/input/the-future-crop-challenge/tasmax_maize_test.parquet\n/kaggle/input/the-future-crop-challenge/pr_maize_train.parquet\n/kaggle/input/the-future-crop-challenge/pr_wheat_test.parquet\n/kaggle/input/the-future-crop-challenge/soil_co2_maize_train.parquet\n/kaggle/input/the-future-crop-challenge/tasmin_maize_test.parquet\n/kaggle/input/the-future-crop-challenge/train_solutions_wheat.parquet\n/kaggle/input/the-future-crop-challenge/tas_maize_train.parquet\n/kaggle/input/the-future-crop-challenge/soil_co2_wheat_test.parquet\n/kaggle/input/the-future-crop-challenge/tasmin_maize_train.parquet\n/kaggle/input/the-future-crop-challenge/rsds_wheat_test.parquet\n/kaggle/input/the-future-crop-challenge/tasmin_wheat_test.parquet\n/kaggle/input/the-future-crop-challenge/tas_maize_test.parquet\n/kaggle/input/the-future-crop-challenge/tasmax_wheat_test.parquet\n/kaggle/input/the-future-crop-challenge/rsds_wheat_train.parquet\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# CropGPT\n\nBelow we dig into Pytorch. \n1. Efficient training starts with a dataset class with data pre-moved onto the GPU (when possible).\n2. ","metadata":{}},{"cell_type":"markdown","source":"## Dataset setup\n\nWe will try to train different architectures using pytorch. We spend some time here defining a dataset class.\nThis will let us train both recurrent networks and transformers later.","metadata":{}},{"cell_type":"code","source":"\nclass PredDataset(Dataset):\n    \"\"\"\n    A pytorch dataset class that transfers all data to GPU, minimising memory transfers during training.\n    Expands static data () to the length of the sequence.\n    \"\"\"\n    def __init__(self, crop: str, mode: str, data_dir: str, device=device):\n        # Read all data files\n        self.prepare_inputs(crop, mode, data_dir, device)\n    \n    def prepare_inputs(self, crop,mode,data_dir,device):\n        tasmax = pd.read_parquet(os.path.join(data_dir, f\"tasmax_{crop}_{mode}.parquet\"))\n        tasmin = pd.read_parquet(os.path.join(data_dir, f\"tasmin_{crop}_{mode}.parquet\"))\n        pr = pd.read_parquet(os.path.join(data_dir, f\"pr_{crop}_{mode}.parquet\"))\n        rsds = pd.read_parquet(os.path.join(data_dir, f\"rsds_{crop}_{mode}.parquet\"))\n        soil_co2 = pd.read_parquet(os.path.join(data_dir, f\"soil_co2_{crop}_{mode}.parquet\"))\n        \n        # Load yield data if in training mode\n        if mode == 'train':\n            self.yield_data = pd.read_parquet(os.path.join(data_dir, f\"{mode}_solutions_{crop}.parquet\"))\n            self.yield_data['crop'] = crop\n            self.yield_data['crop_id'] = 0 if crop == 'maize' else 1\n        else:\n            self.yield_data = pd.DataFrame(tasmax['crop'])\n            self.yield_data['crop_id'] = 0 if crop == 'maize' else 1\n            self.yield_data['yield'] = 0\n            \n        # Preprocess climate data in bulk (shape: num_samples × 240 × 4)\n        climate_data = np.stack([\n            tasmax.iloc[:, 5:].values,\n            tasmin.iloc[:, 5:].values,\n            pr.iloc[:, 5:].values,\n            rsds.iloc[:, 5:].values\n        ], axis=2).astype(np.float32)\n        \n        # Preprocess soil data in bulk\n        soil_continuous = soil_co2[['lon', 'lat', 'co2']].values.astype(np.float32)\n        soil_continuous = np.repeat(soil_continuous[:, np.newaxis, :], 240, axis=1)\n        crop_expanded = np.repeat(self.yield_data['crop_id'].values.reshape(-1,1,1),240,axis=1)\n        yield_expanded = np.repeat(self.yield_data['yield'].values.reshape(-1,1,1),240,axis=1)\n    \n        # Combine climate and soil features (shape: num_samples × 240 × 21)\n        full_input = np.concatenate([climate_data, soil_continuous, crop_expanded,yield_expanded], axis=2)\n        \n        # Move entire dataset to device in one operation\n        self.inputs = torch.tensor(full_input, device=device,dtype=torch.float32)\n\n        #memory management\n        del tasmax, tasmin, pr, rsds, soil_co2, climate_data, soil_continuous, crop_expanded, yield_expanded, full_input\n\n        gc.collect()\n        \n        return None\n        \n    def __getitem__(self, index):\n        # Return precomputed tensors\n        return self.inputs[index]\n\n    def __len__(self):\n        return len(self.inputs)\n\nprint('Loading training data.,. (this may take a while)')\ntrain_wheat = PredDataset('wheat','train', DATA_DIR)\ntrain_maize = PredDataset('maize','train',DATA_DIR)\nprint(train_wheat.inputs.shape)\n\nprint(train_maize.yield_data)\nprint(train_wheat.yield_data)\n#train_wheat = torch.utils.data.subset\n\n#print('Loading test data... (this may take a while)')\n#wheat_test = PredDataset('wheat','test', DATA_DIR, device = 'cpu')\n\nprint('Finished loading')\n\n\n\nn_train = int(train_maize.inputs.shape[0]*0.8)\nn_val = train_maize.inputs.shape[0] - n_train\ntrain_set, val_set = torch.utils.data.random_split(train_maize, [n_train,n_val])\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size = 512, shuffle = True)\nval_loader = torch.utils.data.DataLoader(val_set, batch_size = 512, shuffle = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T23:41:51.873406Z","iopub.execute_input":"2025-11-25T23:41:51.874171Z","iopub.status.idle":"2025-11-25T23:42:39.941800Z","shell.execute_reply.started":"2025-11-25T23:41:51.874149Z","shell.execute_reply":"2025-11-25T23:42:39.941082Z"}},"outputs":[{"name":"stdout","text":"Loading training data.,. (this may take a while)\ntorch.Size([278747, 240, 9])\n        yield   crop  crop_id\nID                           \n0       5.595  maize        0\n1       5.895  maize        0\n2       3.023  maize        0\n3       2.071  maize        0\n4       2.239  maize        0\n...       ...    ...      ...\n349714  6.240  maize        0\n349715  8.926  maize        0\n349716  2.180  maize        0\n349717  7.311  maize        0\n349718  2.118  maize        0\n\n[349719 rows x 3 columns]\n         yield   crop  crop_id\nID                            \n1040990  4.775  wheat        1\n1040991  4.874  wheat        1\n1040992  4.701  wheat        1\n1040993  4.848  wheat        1\n1040994  5.178  wheat        1\n...        ...    ...      ...\n1319732  1.418  wheat        1\n1319733  1.653  wheat        1\n1319734  1.271  wheat        1\n1319735  0.469  wheat        1\n1319736  0.629  wheat        1\n\n[278747 rows x 3 columns]\nFinished loading\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Training transformers\n\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom tqdm import tqdm\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass CropTransformer(nn.Module):\n    def __init__(self, input_dim, d_model, n_heads, n_layers, max_seq_len, dropout=0.1):\n        super().__init__()\n        \n        # RevIN for Input Features (Climate + Soil). \n        # We assume the last column is Yield and might treat it differently.\n        self.revin = RevIN(input_dim - 1) \n        \n        self.input_projection = nn.Linear(input_dim, d_model)\n        self.pos_encoding = nn.Parameter(torch.randn(1, max_seq_len, d_model))\n        \n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=d_model, nhead=n_heads, dim_feedforward=d_model//2, \n            dropout=dropout, batch_first=True, activation='gelu'\n        )\n        self.transformer = nn.TransformerEncoder(encoder_layer, n_layers)\n        self.output_projection = nn.Linear(d_model, input_dim)\n        self.mask_token = nn.Parameter(torch.randn(1, 1, input_dim))\n\n    def forward(self, x, mask_indices=None):\n        batch_size, seq_len, n_feats = x.shape\n        \n        # --- 1. Apply RevIN (Distribution Shift Handling) ---\n        # Strategy: Normalize Inputs (0:-1) to fix distribution shift.\n        # Leave Yield (-1) raw to avoid leakage during the 'Yield Prediction' task.\n        \n        # Split Yield from Features\n        x_feats = x[:, :, :-1]\n        x_yield = x[:, :, -1:]\n        \n        # Normalize Features ONLY\n        x_feats = self.revin.normalize(x_feats)\n        \n        # Recombine\n        x = torch.cat([x_feats, x_yield], dim=-1)\n\n        # --- 2. Apply Masking ---\n        if mask_indices is not None:\n            mask_token_expanded = self.mask_token.expand(batch_size, seq_len, -1)\n            x = torch.where(mask_indices, mask_token_expanded, x)\n\n        # --- 3. Transformer Block ---\n        x = self.input_projection(x) + self.pos_encoding[:, :seq_len, :]\n        x = self.transformer(x)\n        x = self.output_projection(x)\n        \n        # --- 4. Denormalize (Optional) ---\n        # Since we only normalized inputs, we should technically denormalize the \n        # predicted inputs to calculate loss in the original space.\n        \n        pred_feats = x[:, :, :-1]\n        pred_yield = x[:, :, -1:]\n        \n        pred_feats = self.revin.denormalize(pred_feats)\n        \n        # Return recombined full prediction\n        return torch.cat([pred_feats, pred_yield], dim=-1)\n\nclass RevIN(nn.Module):\n    def __init__(self, num_features, eps=1e-5, affine=True):\n        \"\"\"\n        Reversible Instance Normalization.\n        Normalizes the input over the time dimension to handle distribution shift.\n        \"\"\"\n        super(RevIN, self).__init__()\n        self.num_features = num_features\n        self.eps = eps\n        self.affine = affine\n        if self.affine:\n            self._init_params()\n\n    def _init_params(self):\n        self.affine_weight = nn.Parameter(torch.ones(self.num_features))\n        self.affine_bias = nn.Parameter(torch.zeros(self.num_features))\n\n    def _get_statistics(self, x):\n        dim2reduce = 1  # Calculate stats over Sequence Length (dim 1)\n        self.mean = torch.mean(x, dim=dim2reduce, keepdim=True).detach()\n        self.stdev = torch.sqrt(torch.var(x, dim=dim2reduce, keepdim=True, unbiased=False) + self.eps).detach()\n        return self.mean, self.stdev\n\n    def normalize(self, x):\n        mean, stdev = self._get_statistics(x)\n        x = (x - mean) / stdev\n        if self.affine:\n            x = x * self.affine_weight + self.affine_bias\n        return x\n\n    def denormalize(self, x):\n        if self.affine:\n            x = (x - self.affine_bias) / (self.affine_weight + self.eps)\n        x = x * self.stdev + self.mean\n        return x\n\ndef create_dual_objective_mask(inputs, yield_idx=-1, block_size=20, random_prob=0.15):\n    \"\"\"\n    Splits the batch into two objectives:\n    1. Yield Prediction (First half of batch)\n    2. Structure Learning (Second half of batch: Random Index OR Block Masking)\n    \"\"\"\n    batch_size, seq_len, n_feats = inputs.shape\n    mask = torch.zeros_like(inputs, dtype=torch.bool)\n    split_idx = batch_size // 2\n    mask[:split_idx, :, yield_idx] = True\n    use_block = torch.rand(batch_size - split_idx) > 0.5\n    for i in range(split_idx, batch_size):\n        is_block_mode = use_block[i - split_idx]\n        if is_block_mode:\n            start = torch.randint(0, seq_len - block_size, (1,)).item()\n            mask[i, start:start+block_size, :] = True\n        else:\n            rand_time_mask = torch.rand(seq_len) < random_prob\n            mask[i, rand_time_mask, :] = True\n    return mask, split_idx\n\ndef train_one_epoch(model, dataloader, optimizer, scheduler, device, yield_idx=-1):\n    model.train()\n    epoch_yield_losses = []\n    epoch_struct_losses = []\n    \n    pbar = tqdm(dataloader, desc=\"Training\")\n    for inputs in pbar:\n        mask, split_idx = create_dual_objective_mask(inputs, yield_idx=yield_idx)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs, mask_indices=mask)\n        \n        # 1. Yield Loss\n        yield_preds = outputs[:split_idx]\n        yield_targets = inputs[:split_idx]\n        yield_mask = mask[:split_idx]\n        \n        if yield_mask.any():\n            loss_yield = nn.functional.mse_loss(yield_preds[yield_mask], yield_targets[yield_mask])\n        else:\n            loss_yield = torch.tensor(0.0, device=device, requires_grad=True)\n        \n        # 2. Structure Loss\n        struct_preds = outputs[split_idx:]\n        struct_targets = inputs[split_idx:]\n        struct_mask = mask[split_idx:]\n        \n        if struct_mask.any():\n            loss_struct = 1e-3*nn.functional.mse_loss(struct_preds[struct_mask], struct_targets[struct_mask])\n        else:\n            loss_struct = torch.tensor(0.0, device=device, requires_grad=True)\n        \n        total_loss = loss_yield + loss_struct\n        total_loss.backward()\n        optimizer.step()\n        scheduler.step()\n        \n        epoch_yield_losses.append(loss_yield.item())\n        epoch_struct_losses.append(loss_struct.item())\n        \n        pbar.set_postfix({'L_Yield': f\"{loss_yield.item():.4f}\", 'L_Struct': f\"{loss_struct.item():.4f}\"})\n        \n    return epoch_yield_losses, epoch_struct_losses\n\ndef plot_training_history(yield_history, struct_history):\n    plt.figure(figsize=(12, 5))\n    def smooth(scalars, weight=0.9):\n        if not scalars: return []\n        last = scalars[0]\n        smoothed = []\n        for point in scalars:\n            smoothed_val = last * weight + (1 - weight) * point\n            smoothed.append(smoothed_val)\n            last = smoothed_val\n        return smoothed\n\n    plt.plot(yield_history, alpha=0.3, color='blue')\n    plt.plot(struct_history, alpha=0.3, color='orange')\n    plt.plot(smooth(yield_history), label='Yield Prediction Loss', color='blue', linewidth=2)\n    plt.plot(smooth(struct_history), label='Structure Reconstruction Loss', color='orange', linewidth=2)\n    plt.title(\"Loss Trends per Iteration\")\n    plt.xlabel(\"Training Iterations (Batches)\")\n    plt.ylabel(\"MSE Loss\")\n    plt.legend()\n    plt.grid(True, which='both', alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n\nif __name__ == \"__main__\":\n    # Hyperparameters\n    BATCH_SIZE = 512\n    SEQ_LEN = 240\n    N_FEATURES = 8\n    D_MODEL = 32\n    N_HEADS = 4\n    N_LAYERS = 2\n    EPOCHS = 10\n    LR = 1e-6\n    max_LR = 1e-2\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # we do a bit of dataset splitting to evaluate how well the training is going\n    n_train = int(len(ds_wheat.inputs)*0.8)\n    n_val = len(ds_wheat.inputs)-n_train\n    \n    train_wheat = torch.utils.data.Subset(ds_wheat, range(n_train))\n    val_wheat = torch.utils.data.Subset(ds_wheat,range(n_train,n_train+n_val))\n    train_loader = DataLoader(train_wheat, batch_size=BATCH_SIZE, shuffle=True)\n    val_loader = DataLoader(train_wheat, batch_size=BATCH_SIZE, shuffle=False)\n    \n    model = CropTransformer(N_FEATURES, D_MODEL, N_HEADS, N_LAYERS, SEQ_LEN).to(device, dtype=torch.float32)\n    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-5)\n    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_LR, \n                                              steps_per_epoch=len(train_loader), \n                                              epochs=EPOCHS)\n\n    all_yield_losses = []\n    all_struct_losses = []\n\n    print(\"Starting Training with Split Batch Strategy...\")\n    for epoch in range(EPOCHS):\n        model.train()\n        y_losses, s_losses = train_one_epoch(model, train_loader, \n                                             optimizer, scheduler, device)\n        all_yield_losses.extend(y_losses)\n        all_struct_losses.extend(s_losses)\n        if (epoch + 1) % 10 == 0:\n            print(f\"Epoch {epoch+1} Avg | Yield: {np.mean(y_losses):.4f} | Struct: {np.mean(s_losses):.4f}\")\n            val_losses = [] #compute validation loss\n            model.eval()\n            with torch.no_grad():\n                for val_inputs in val_loader:\n                    yield_mask = torch.zeros_like(val_inputs, dtype = torch.bool)\n                    yield_mask[:,:,-1] = True\n                    val_outputs = model(val_inputs, yield_mask)\n                    val_loss = nn.functional.mse_loss(val_outputs[yield_mask], \n                                                      val_inputs[:,:,-1].flatten())\n                    val_losses.append(val_loss.item())\n            print(f'Validation loss:{np.mean(val_losses)}')\n    plot_training_history(all_yield_losses, all_struct_losses)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-25T22:15:47.343Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission\n\n\n","metadata":{}},{"cell_type":"code","source":"#submission\n\nsubmission_csv = pd.read_csv('/kaggle/input/the-future-crop-challenge/sample_submission.csv')\n\n\ndata =  PredDataset('maize','test',DATA_DIR)\nlen(data)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-25T22:15:47.343Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_csv[:553878]","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-25T22:15:47.344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"553878 + 691271","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-25T22:15:47.344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}